\documentclass[sigconf,nonacm]{acmart}

\AtBeginDocument{%
\providecommand\BibTeX{{%
\normalfont B\kern-0.5em{\scshape i\kern-0.25em b}\kern-0.8em\TeX}}}



\newcommand{\scores}{\textsc{SCORES}}

\usepackage{verbatim}
\usepackage[linesnumbered, boxed, resetcount]{algorithm2e}
\usepackage{hyperref}

\usepackage{booktabs}
\usepackage{listings}
\usepackage{xcolor}

\usepackage{amsmath}
\usepackage{graphicx}

%* Package settings
\hypersetup{
colorlinks  = true,
linkcolor   = black,
urlcolor    = red,
}

\begin{document}

\title{Activity Bot's Catch Game\\
Ultrasonic Sensor Fusion for Object Tracking}

\author{Bruno Silva  }
\email{bruno.silva1@student.um.si}
\affiliation{%
    \institution{Faculty of Electrical \\Engineering and Computer Science,\\
    University of Maribor\\Koro\v{s}ka cesta 46}
    \city{SI-2000 Maribor}
    \country{Slovenia}
    }

    
    
    \begin{abstract}
    
This paper describes the development of two small robots from \textit{Parallax}, the \textit{Activity
Bots} - a seeker (Figure \ref{fig:Seeker}) and a runner (Figure \ref{fig:Runner})
- that use ultrasonic sensors to play the \textit{Catch game}. The seeker robot was
programmed to detect the runner robot and chase it, while the runner robot was
programmed to evade the seeker robot. The paper discusses the design and
construction of the robots and the algorithms used to control their movements.
The results of experiments conducted to test the robots' performance in the game
are presented and analyzed. The experiments show that the seeker robot was able
to detect and pursue the runner robot successfully.
This paper also goes briefly on how to incorporate the workflow of parallax's
robots programming in the popular text editor VScode.
 

    \end{abstract}
    
    \maketitle


    \keywords{\LaTeX, template, paper, conference }

\section{Introduction}

    Tracking and detection algorithms are the base for many
    applications in robotics field. There are many examples of other studies
    backing this up, such as the use of Yolo's deep learning algorithms for
    object detection \cite{r1}, or the use of tracking algorithms for robot
    control \cite{control_robot}. While RGBD cameras or 2D/3D LiDARs are often
    the preferred choice for most applications\cite{r2}, ultrasonic sensors, even though
    simple and quite less powerful, are sometimes a good alternative due to
    their much more affordable price\cite{Zhmud_2018}. The approach used in this research has
    some reassemblance with the working principles of stereo cameras\cite{panich2010comparison}. Using 1
    ultrasonic sensor proved insufficient to predict the target's direction.
    Switching to 2 sensors and measuring deltas instead of absolute values
    allowed the seeker to perceive the direction the target was coming from.
    Some studies show the credibility of fusing ultrasonic sensors \cite{ultrasonic_fusion}.
    This working principle will be further expanded on in the seeker's robot
    chapter of this paper.

\begin{figure}[h]
    \centering
    \includegraphics[scale=0.1]{resources/Seeker_robot/4.jpeg}
    \caption{\label{fig:Seeker}Seeker Robot.}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[scale=0.1]{resources/Runner_robot.jpeg}
    \caption{\label{fig:Runner}Runner Robot. PLACEHOLDER IMG}
\end{figure}

\section{Developing Environment}

      This chapter is meant to explain the working environment of the
      programming
      of Parallax's robots and the work flow that was used throughout this
      project
      

      \subsection{SimpleIDE}

      SimpleIDE is Parallax's official developing platform. As the name
      suggests, it's a rather feature lacking IDE as shown in \ref{fig:simple_ide}. Basic features like autocompletion, keyword highlight, or even
      error squiggles are not present. Lack of customizability is what sets it
      behind, not being simple. Other editors like Vim are also pretty simple by
      default and are very popular due to their unmatched customizability ceiling. 
      \begin{figure}[h]
            \centering
            \includegraphics[scale=0.1]{resources/simple_ide.png}
            \caption{\label{fig:simple_ide}SimpleIDE working environment.}
      \end{figure}


      \subsection{VScode Integration}

      Fortunately, it is possible, with some workarounds, to migrate the grand
      majority of the workflow into a more popular environment like VScode.
      
      \begin{enumerate}
            \item PlatformIO
                  \begin{itemize}
                        \item PlatformIO's IDE is a VScode
                        extension which transforms VScode into a IDE capable of
                        fully programming a wide range of microcontrollers, from
                        code writting to EEPROM flashing. There's a platform
                        there for working the Parallax's
                        microcontrollers (\href{https://github.com/msquirogac/platform-propeller}{Github}).
                        However, upon exhaustive testing this platform seems to
                        be a half finished attempt which doesn't work.
                  \end{itemize}
            \item VScode
                  \begin{itemize}
                        \item One way is to add SimpleIDE's libraries to the
                        default C path for the default C libraries. This
                        approach is better for long term development, but on
                        this project wasn't used.

                        \item Another way is to import the libraries straight
                        into the project's folder, allowing VScode to treat them
                        as user built libraries.
                        
                        This was the approach used. To replicate the following
                        folders have to be copied to the project folder:
                              \begin{lstlisting}[language=bash]
$ /home/${USER}/Documents/SimpleIDE/
Learn
$ /opt/parallax
                                    \end{lstlisting}
                              It's important to note that this applies only for Ubuntu
                                    based systems and that both these folders should be
                                    added to the repository's \textit{.gitignore} as they
                                    are quite big and not important to the project itself.
                  \end{itemize}
      \end{enumerate}


\section{Seeker Robot}

The core of the seeker's algorithm is these 2 steps:
\begin{enumerate}
      \item Assessing targets in range of ultrasonic sensors;
      
      This involves stopping, getting 2 measurements from each sensor spaced by
      a predefined $\Delta t\space[s]$, calculating the $\Delta d\space[cm]$ from the right and
      left sensor and figure out which direction the target is coming from and
      outputting accordingly.
      \item Giving moving order to the servos to chase the target. In this step the
      purpose is to, given the direction the target crossed from, tune how much
      the robot should rotate and go forward. This ideally would be dynamically
      controlled, but since the robot cannot know how fast the target crossed,
      it has to be manually tuned for a given target velocity.
\end{enumerate}

\subsection{Assessing Targets}

The first thing this function does is assure the robot is still before reading
the differential distance measures. The code could account for the velocity of
the seeker and correct the measure, but that would be mathematically a lot more
challenging.

Then, after reading the distance measurements, the robot could be left with 5
possible case-scenarios given the 2 differential measures :

\begin{enumerate}
     \item $\Delta D_L<0 \wedge \Delta D_R \approx 0$ \\ This would mean the
     target came from out of range and is started being detected the by left
     sensor, since the measure distance reduced. The robot should thus
     turn \textbf{RIGHT};
     
     \item $\Delta D_L\approx 0\wedge \Delta D_R < 0$ \\ This would mean the same
     as case 1, but instead the target is approaching from the right, so the
     robot should turn \textbf{LEFT};

     \item $\Delta D_L>0\wedge \Delta D_R \approx 0$ \\ This would mean the
     target was already in sight of the left sensor and left suddenly to the
     left, allowing the sensor to see into the further away background. This
     would mean the robot should turn \textbf{LEFT};
     
     \item $\Delta D_L\approx 0 \wedge \Delta D_R > 0$ \\ This would mean the
     target was already in sight of the right sensor and left suddenly to the
     right, allowing the sensor to see into the further away background. This
     would mean the robot should turn \textbf{RIGHT};

     \item $|\Delta D_L|>0\wedge |\Delta D_R| > 0$ \\ This would mean that the
     target is currently in front of the robot and is either getting further
     away or getting closer. Either way, for the seeker robot the order should
     be to go \textbf{forward}.
\end{enumerate}

In practice, a \textit{threshold} was used instead of 0, to account for sensor
measurement error.


\subsection{Measuring distances}

Initially, in order to assure the robot could always read the latest reading from the
sensor when needing to evaluate distances, and to take advantage of the
parallax's multicore chip, the sensor data was being stored on a global variable
that was constantly being updates parallel to the code. The code for acquiring
data was running on a separate core. 
However, due to timing reasons, this proved to be more harmful to the overall
performance of the robot. In the end, whenever the robot isn't actively pursuing
the target, he is in a semi-idle state doing nothing other than to measure
distances to try to identify a potential target.

\subsection{Issues with the current implementation}
\label{chap: issues}
\begin{itemize}
      \item 
      As of right now, the seeker isn't identifying how close the target is. As of
      right now, the robot upon identifying the target's direction, its servos get an
      input for a set amount of time at a set power. A runner coming into frame
      further away should result in a smaller turn time while another closer away
      should result in a sharper turn.
      Finding a function that correlates the distance to the correct turn amount
      is not an easy task tho, a trial and error approach could be used, but
      such approach is reckoned to be too volatile and sensitive to environment changes.

      \item Using ultrasonic sensors instead of cameras basically limits the
      robot perception field into a line instead of spacial. This is means if for
      some reason the runner gets completely out of the runner field of view,
      the seeker becomes clueless again until the runner comes back into frame
      again.
      One approach to this problem could be to have the seeker pan around itself
      whenever he got more than a set amount of repeated null differential
      distances readings.

      \item The ultrasonic sensors used are not very accurate and from time to
      time yield outrageous readings, the robot if left facing a plain wall
      still for a big enough period of time, its almost certain that he will
      spontaneously turn because of an inaccurate reading. The sensors were
      replaced and switched and the problem remained.
\end{itemize}



\section{Runner Robot}

This robot does not possess any intelligence, it's just working as dummy robot
that goes around in circles to provide the seeker something to follow. The only
possible mounting position that would somewhat suit this robot is facing
backwards, as there is never a scenario where the runner wants to be facing the
seeker, but even then the runner ideally shouldn't be directly in front of the 
seeker, since it would be in its perception field. 

\section{Experiments and results}

The following section goes over how the algorithm performed when faced with a
few tests. It was tested the reaction time and the accuracy of the assessing,
meaning if the seeker determined the right runner's direction.\footnote[1]{There
are demo videos in the Github Repository}


\subsection{Reaction time}
\label{chap:reaction}

It's important to note the following : the reaction time is mainly controlled by
the delay between differential measures, \textit{$ \Delta T$}. In theory with a really low $ \Delta T$, the
response time would be really great. In practice, this proved to have a lot more
drawbacks:
\begin{itemize}
      \item The runner robot is not 100\% opaque, meaning its hollowness makes
      the robot's behavior with a low  $ \Delta T$ unpredictable.

      \item A low $ \Delta T$ also makes the robot's behavior very jittery and nervous.
      
\end{itemize}

Nevertheless, with a delay of \textit{50ms}, here are some measurements of the
response time with a moving object.



\begin{table}[h]
      \caption[short]{Results of the reaction time experiment\footnote[2]{}\footnote[3]{}}
      \begin{tabular}{l|c|r}
            \toprule
            Trial     &     Runner Speed\footnote[4]{}     &     Reaction time[s]\\
            \midrule    
            1     &     10     &     0.3\\
            2     &     20     &     0.4\\
            3     &     50     &     0.6\\
            4     &     70     &     0.7\\
            5     &     100    &     -\\
            6     &     150    &     -\\
            7     &     200    &     -\\
            \bottomrule
      \end{tabular}
\end{table}

Each time was measured from the instant that the runner entered the direct line
of sight of the seeker until the start of its movement.
      
\footnotetext[2]{Each trial consisted of 3 measures and the written reaction time is the mean average of the measurements for each speed}
\footnotetext[3]{The time was measured with by recording at the 60fps on a DLSR camera and then analyzed in Adobe Premiere. Still,this results are merely approximate and meant to be taken as qualitative}
\footnotetext[4]{This speed is the integer given to the servos of the robot, it's a function prebuilt in the library as the author had no way of accurately measuring the runners speed }


 
\subsection{Accuracy of target assessing}

To test the seeker's accuracy, a series of objects approached the seeker from
different angles and speeds and here are some results:

\begin{table}[h]
      \caption[short]{Results of the accuracy experiment}
      \begin{tabular}{l|c|c|r}
            \toprule
            Trial     &     Runner's Speed  & Approach Direction   & \%
            of accurate response\\
            \midrule    
            1         &     10              & Right   &   80\\
            2         &     10              & Left    &   80\\
            3         &     20              & Right   &   60\\
            4         &     20              & Left    &   50\\
            5         &     70              & Right   &   30\\
            6         &     70              & Left    &   20\\
            \bottomrule
      \end{tabular}
\end{table}

\subsection{Discussion of results}

From the reaction time experiment, it could be seen that the robot does not
react to objects that move at speeds faster than 70\footnotemark[4] and does not
answer accurately neither for objects moving at those speeds. How the other
hand, for low speeds, the robot's algorithm is working within margin of error.

This would suggest that the solution implemented is not enough for more
demanding environments, which might very likely be due to the points discussed
in \autoref{chap: issues}. If those were to be tackled in a future
implementation of this algorithm, its plausible that the results would be much
better.

Regardless, the results were enough to proof that the concept of ultrasonic
sensor fusion for object tracking has some potential. At the current
implementation it works for low speeds decently\footnotemark[1].

\section{Conclusions}

In conclusion, the purpose of this paper was to assess  whether ultrasonic
sensor fusion for tracking objects would be viable. The method adopted showed
some potential and interesting results, however it proved insufficient in its
current state for fast moving targets. The reaction speed could be increased by
increasing the delay between measurements but at the cost the accuracy, as
explained in \autoref{chap:reaction}.\\

Overall the research was successful at demonstrating a proof of concept and if
the issues referred in \autoref{chap: issues} are tackled, the algorithm will
work much better and at a much lower price than a more sophisticated sensor such
as a RGBD camera or LiDar.



The final project code is accesible on \textit{\href{https://github.com/brunofavs/propeller_cath_game}{Github}}. 

\bibliographystyle{ACM-Reference-Format}
\bibliography{references}

\end{document}
